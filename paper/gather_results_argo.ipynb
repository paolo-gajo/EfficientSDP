{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/paper_results_xavier_uniform/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_name_dict = {\n",
    "    'ade': 'ADE',\n",
    "    'conll04': 'CoNLL04',\n",
    "    'scierc': 'SciERC',\n",
    "    'yamakata': 'ERFGC',\n",
    "}\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "# pd.set_option('display.max_rows', 999)\n",
    "def load_results(walk_path: str):\n",
    "    records = []\n",
    "    metric_list = ['tagger_results', 'parser_labeled_results', 'parser_unlabeled_results']\n",
    "    for root, dirs, files in os.walk(walk_path):\n",
    "        for F in files:\n",
    "            filename = os.path.join(root, F)\n",
    "            if filename.endswith('config.json'):                \n",
    "                config_dict = json.load(open(filename))\n",
    "                benchmark_dict = json.load(open(filename.replace('config.json', 'test_results_benchmark.json')))\n",
    "                try:\n",
    "                    params = benchmark_dict['learnable params']\n",
    "                except:\n",
    "                    params = 0\n",
    "                val_results = config_dict['val_results']\n",
    "                test_results = config_dict['test_results']\n",
    "                config = config_dict['config']\n",
    "\n",
    "                for metric in metric_list:\n",
    "                    parser_rnn_type = config['parser_rnn_type']\n",
    "                    par_rnn_h = config['parser_rnn_hidden_size']\n",
    "                    records.append({\n",
    "                        'metric': metric,\n",
    "                        'val_prec': val_results[metric]['P'],\n",
    "                        'val_recall': val_results[metric]['R'],\n",
    "                        'val_f1': val_results[metric]['F1'],\n",
    "                        'test_prec': test_results[metric]['P'],\n",
    "                        'test_recall': test_results[metric]['R'],\n",
    "                        'test_f1': test_results[metric]['F1'],\n",
    "                        'name': config['model_name'],\n",
    "                        'freeze_enc': 'FT' if config['freeze_encoder'] == 0 else 'frozen',\n",
    "                        'params': round(params / 1e6, 2),\n",
    "                        'data': config['dataset_name'],\n",
    "                        'tag_emb_type': config['tag_embedding_type'],\n",
    "                        # 'lora': 'LoRA' if config['use_lora'] == 1 else '/',\n",
    "                        # 'tag_emb': config['use_tag_embeddings_in_parser'],\n",
    "                        'tag_rnn': config['use_tagger_rnn'],\n",
    "                        'par_rnn': parser_rnn_type.upper() if parser_rnn_type != 'none' else '/',\n",
    "                        'par_rnn_l': config['parser_rnn_layers'],\n",
    "                        'mlp_h': config['arc_representation_dim'],\n",
    "                        'arc_norm': config['arc_norm'],\n",
    "                        'par_rnn_h': par_rnn_h if par_rnn_h != 'none' else 0,\n",
    "                        'par_type': config['parser_type'],\n",
    "                        'par_gnn_layers': config['gnn_enc_layers'],\n",
    "                        \n",
    "                        # 'par_res': config['parser_residual'],\n",
    "                        'seed': config['seed'],\n",
    "                        'training_steps': config['training_steps'],\n",
    "                    })\n",
    "    \n",
    "    # Create DataFrame from all collected records at the end\n",
    "    df_aggregate = pd.DataFrame.from_records(records)\n",
    "    # print(df_aggregate.columns)\n",
    "    return df_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new results post May 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "bert-large-uncased            62\n",
       "microsoft/deberta-v3-large    54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walk_path = \"/home/pgajo/projects/def-hsajjad/pgajo/Multitask-RFG-torch/results_ft_steps_2000\"\n",
    "df = load_results(walk_path)\n",
    "df = df[df['metric'] == 'parser_labeled_results']\n",
    "df = df.sort_values(by=[\n",
    "    'data',\n",
    "    'tag_emb_type',\n",
    "    'par_rnn_l',\n",
    "    'mlp_h',\n",
    "    'arc_norm', \n",
    "    'test_f1',\n",
    "    ])\n",
    "df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>name</th>\n",
       "      <th>freeze_enc</th>\n",
       "      <th>params</th>\n",
       "      <th>data</th>\n",
       "      <th>tag_emb_type</th>\n",
       "      <th>tag_rnn</th>\n",
       "      <th>par_rnn</th>\n",
       "      <th>par_rnn_l</th>\n",
       "      <th>mlp_h</th>\n",
       "      <th>arc_norm</th>\n",
       "      <th>par_rnn_h</th>\n",
       "      <th>par_type</th>\n",
       "      <th>par_gnn_layers</th>\n",
       "      <th>seed</th>\n",
       "      <th>training_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.77</td>\n",
       "      <td>ade</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.77</td>\n",
       "      <td>ade</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.77</td>\n",
       "      <td>ade</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.4188</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.64</td>\n",
       "      <td>ade</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.77</td>\n",
       "      <td>ade</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.92</td>\n",
       "      <td>yamakata</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4169</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.92</td>\n",
       "      <td>yamakata</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.92</td>\n",
       "      <td>yamakata</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.92</td>\n",
       "      <td>yamakata</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.92</td>\n",
       "      <td>yamakata</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     metric  val_prec  val_recall  val_f1  test_prec  \\\n",
       "154  parser_labeled_results  0.1643    0.1641      0.1642  0.2554      \n",
       "160  parser_labeled_results  0.1643    0.1641      0.1642  0.2554      \n",
       "172  parser_labeled_results  0.1643    0.1641      0.1642  0.2554      \n",
       "163  parser_labeled_results  0.5035    0.4188      0.4572  0.4922      \n",
       "151  parser_labeled_results  0.7609    0.7502      0.7555  0.7426      \n",
       "..                      ...     ...       ...         ...     ...      \n",
       "241  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "238  parser_labeled_results  0.4795    0.4486      0.4636  0.4352      \n",
       "244  parser_labeled_results  0.6757    0.6747      0.6752  0.6435      \n",
       "217  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "220  parser_labeled_results  0.6727    0.6556      0.6640  0.6253      \n",
       "\n",
       "     test_recall  test_f1                        name freeze_enc  params  \\\n",
       "154  0.2548       0.2551   bert-large-uncased          FT         336.77   \n",
       "160  0.2548       0.2551   bert-large-uncased          FT         336.77   \n",
       "172  0.2548       0.2551   bert-large-uncased          FT         336.77   \n",
       "163  0.3798       0.4288   microsoft/deberta-v3-large  FT         435.64   \n",
       "151  0.7284       0.7354   bert-large-uncased          FT         336.77   \n",
       "..      ...          ...                  ...          ..            ...   \n",
       "241  0.0000       0.0000   bert-large-uncased          FT         336.92   \n",
       "238  0.4000       0.4169   bert-large-uncased          FT         336.92   \n",
       "244  0.6435       0.6435   bert-large-uncased          FT         336.92   \n",
       "217  0.0000       0.0000   bert-large-uncased          FT         336.92   \n",
       "220  0.6177       0.6215   bert-large-uncased          FT         336.92   \n",
       "\n",
       "         data tag_emb_type  tag_rnn par_rnn  par_rnn_l  mlp_h  arc_norm  \\\n",
       "154  ade       embedding    0        LSTM    0          500    0          \n",
       "160  ade       embedding    0        LSTM    0          500    0          \n",
       "172  ade       embedding    0        LSTM    0          500    0          \n",
       "163  ade       embedding    0        LSTM    0          500    0          \n",
       "151  ade       embedding    0        LSTM    0          500    0          \n",
       "..   ...             ...   ..         ...   ..          ...   ..          \n",
       "241  yamakata  linear       0        LSTM    0          500    0          \n",
       "238  yamakata  linear       0        LSTM    0          500    0          \n",
       "244  yamakata  linear       0        LSTM    0          500    0          \n",
       "217  yamakata  linear       0        LSTM    0          500    1          \n",
       "220  yamakata  linear       0        LSTM    0          500    1          \n",
       "\n",
       "     par_rnn_h par_type  par_gnn_layers  seed  training_steps  \n",
       "154  400        simple   0               2     2000            \n",
       "160  400        simple   0               1     2000            \n",
       "172  400        simple   0               0     2000            \n",
       "163  400        simple   0               4     2000            \n",
       "151  400        simple   0               3     2000            \n",
       "..   ...           ...  ..              ..      ...            \n",
       "241  400        simple   0               2     2000            \n",
       "238  400        simple   0               0     2000            \n",
       "244  400        simple   0               3     2000            \n",
       "217  400        simple   0               1     2000            \n",
       "220  400        simple   0               2     2000            \n",
       "\n",
       "[116 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>name</th>\n",
       "      <th>freeze_enc</th>\n",
       "      <th>params</th>\n",
       "      <th>data</th>\n",
       "      <th>tag_emb_type</th>\n",
       "      <th>tag_rnn</th>\n",
       "      <th>par_rnn</th>\n",
       "      <th>par_rnn_l</th>\n",
       "      <th>mlp_h</th>\n",
       "      <th>arc_norm</th>\n",
       "      <th>par_rnn_h</th>\n",
       "      <th>par_type</th>\n",
       "      <th>par_gnn_layers</th>\n",
       "      <th>seed</th>\n",
       "      <th>training_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6413</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>FT</td>\n",
       "      <td>336.81</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     metric  val_prec  val_recall  val_f1  test_prec  \\\n",
       "286  parser_labeled_results  0.0265    0.0110      0.0156  0.0000      \n",
       "253  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "247  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "244  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "331  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "328  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "325  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "322  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "262  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "271  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "274  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "295  parser_labeled_results  0.2119    0.1046      0.1400  0.1681      \n",
       "307  parser_labeled_results  0.6868    0.6477      0.6667  0.5969      \n",
       "280  parser_labeled_results  0.6319    0.5890      0.6097  0.6076      \n",
       "301  parser_labeled_results  0.7220    0.7101      0.7160  0.6610      \n",
       "259  parser_labeled_results  0.7450    0.6862      0.7144  0.7253      \n",
       "\n",
       "     test_recall  test_f1                name freeze_enc  params     data  \\\n",
       "286  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "253  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "247  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "244  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "331  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "328  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "325  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "322  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "262  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "271  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "274  0.0000       0.0000   bert-large-uncased  FT         336.81  conll04   \n",
       "295  0.0897       0.1170   bert-large-uncased  FT         336.81  conll04   \n",
       "307  0.5800       0.5883   bert-large-uncased  FT         336.81  conll04   \n",
       "280  0.5740       0.5903   bert-large-uncased  FT         336.81  conll04   \n",
       "301  0.6413       0.6510   bert-large-uncased  FT         336.81  conll04   \n",
       "259  0.6592       0.6907   bert-large-uncased  FT         336.81  conll04   \n",
       "\n",
       "    tag_emb_type  tag_rnn par_rnn  par_rnn_l  mlp_h  arc_norm  par_rnn_h  \\\n",
       "286  embedding    0        LSTM    0          500    0         400         \n",
       "253  embedding    0        LSTM    0          500    1         400         \n",
       "247  embedding    0        LSTM    0          500    1         400         \n",
       "244  embedding    0        LSTM    0          500    1         400         \n",
       "331  linear       0        LSTM    0          500    0         400         \n",
       "328  linear       0        LSTM    0          500    0         400         \n",
       "325  linear       0        LSTM    0          500    0         400         \n",
       "322  linear       0        LSTM    0          500    0         400         \n",
       "262  linear       0        LSTM    0          500    1         400         \n",
       "271  linear       0        LSTM    0          500    1         400         \n",
       "274  linear       0        LSTM    0          500    1         400         \n",
       "295  embedding    0        LSTM    0          500    0         400         \n",
       "307  embedding    0        LSTM    0          500    0         400         \n",
       "280  linear       0        LSTM    0          500    1         400         \n",
       "301  embedding    0        LSTM    0          500    0         400         \n",
       "259  embedding    0        LSTM    0          500    1         400         \n",
       "\n",
       "    par_type  par_gnn_layers  seed  training_steps  \n",
       "286  simple   0               0     2000            \n",
       "253  simple   0               3     2000            \n",
       "247  simple   0               2     2000            \n",
       "244  simple   0               1     2000            \n",
       "331  simple   0               1     2000            \n",
       "328  simple   0               2     2000            \n",
       "325  simple   0               3     2000            \n",
       "322  simple   0               0     2000            \n",
       "262  simple   0               0     2000            \n",
       "271  simple   0               1     2000            \n",
       "274  simple   0               2     2000            \n",
       "295  simple   0               1     2000            \n",
       "307  simple   0               3     2000            \n",
       "280  simple   0               3     2000            \n",
       "301  simple   0               2     2000            \n",
       "259  simple   0               0     2000            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>name</th>\n",
       "      <th>freeze_enc</th>\n",
       "      <th>params</th>\n",
       "      <th>data</th>\n",
       "      <th>tag_emb_type</th>\n",
       "      <th>tag_rnn</th>\n",
       "      <th>par_rnn</th>\n",
       "      <th>par_rnn_l</th>\n",
       "      <th>mlp_h</th>\n",
       "      <th>arc_norm</th>\n",
       "      <th>par_rnn_h</th>\n",
       "      <th>par_type</th>\n",
       "      <th>par_gnn_layers</th>\n",
       "      <th>seed</th>\n",
       "      <th>training_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.6290</td>\n",
       "      <td>0.5904</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.6257</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.6322</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7361</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.6819</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.6143</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.6128</td>\n",
       "      <td>0.6647</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.6183</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.7138</td>\n",
       "      <td>0.6114</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.6817</td>\n",
       "      <td>0.6367</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>embedding</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>parser_labeled_results</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>microsoft/deberta-v3-large</td>\n",
       "      <td>FT</td>\n",
       "      <td>435.68</td>\n",
       "      <td>conll04</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>simple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     metric  val_prec  val_recall  val_f1  test_prec  \\\n",
       "238  parser_labeled_results  0.0000    0.0000      0.0000  0.0000      \n",
       "298  parser_labeled_results  0.7500    0.4018      0.5233  0.6201      \n",
       "277  parser_labeled_results  0.6774    0.6587      0.6679  0.6290      \n",
       "310  parser_labeled_results  0.6861    0.6257      0.6545  0.6322      \n",
       "313  parser_labeled_results  0.6633    0.6073      0.6341  0.6592      \n",
       "319  parser_labeled_results  0.7361    0.6294      0.6785  0.6811      \n",
       "292  parser_labeled_results  0.6950    0.6440      0.6686  0.6599      \n",
       "316  parser_labeled_results  0.6944    0.6587      0.6761  0.6496      \n",
       "265  parser_labeled_results  0.7112    0.6550      0.6819  0.6919      \n",
       "289  parser_labeled_results  0.7261    0.6128      0.6647  0.6847      \n",
       "256  parser_labeled_results  0.7506    0.6183      0.6781  0.7138      \n",
       "250  parser_labeled_results  0.7299    0.6495      0.6874  0.6960      \n",
       "283  parser_labeled_results  0.6817    0.6367      0.6584  0.6779      \n",
       "241  parser_labeled_results  0.7250    0.6385      0.6790  0.7107      \n",
       "304  parser_labeled_results  0.7233    0.6716      0.6965  0.6967      \n",
       "268  parser_labeled_results  0.7194    0.6679      0.6927  0.7209      \n",
       "\n",
       "     test_recall  test_f1                        name freeze_enc  params  \\\n",
       "238  0.0000       0.0000   microsoft/deberta-v3-large  FT         435.68   \n",
       "298  0.3782       0.4698   microsoft/deberta-v3-large  FT         435.68   \n",
       "277  0.5904       0.6091   microsoft/deberta-v3-large  FT         435.68   \n",
       "310  0.5934       0.6122   microsoft/deberta-v3-large  FT         435.68   \n",
       "313  0.6188       0.6384   microsoft/deberta-v3-large  FT         435.68   \n",
       "319  0.6099       0.6435   microsoft/deberta-v3-large  FT         435.68   \n",
       "292  0.6353       0.6474   microsoft/deberta-v3-large  FT         435.68   \n",
       "316  0.6457       0.6477   microsoft/deberta-v3-large  FT         435.68   \n",
       "265  0.6143       0.6508   microsoft/deberta-v3-large  FT         435.68   \n",
       "289  0.6233       0.6526   microsoft/deberta-v3-large  FT         435.68   \n",
       "256  0.6114       0.6586   microsoft/deberta-v3-large  FT         435.68   \n",
       "250  0.6263       0.6593   microsoft/deberta-v3-large  FT         435.68   \n",
       "283  0.6637       0.6707   microsoft/deberta-v3-large  FT         435.68   \n",
       "241  0.6428       0.6750   microsoft/deberta-v3-large  FT         435.68   \n",
       "304  0.6592       0.6774   microsoft/deberta-v3-large  FT         435.68   \n",
       "268  0.6562       0.6870   microsoft/deberta-v3-large  FT         435.68   \n",
       "\n",
       "        data tag_emb_type  tag_rnn par_rnn  par_rnn_l  mlp_h  arc_norm  \\\n",
       "238  conll04  embedding    0        LSTM    0          500    1          \n",
       "298  conll04  embedding    0        LSTM    0          500    0          \n",
       "277  conll04  linear       0        LSTM    0          500    1          \n",
       "310  conll04  linear       0        LSTM    0          500    0          \n",
       "313  conll04  linear       0        LSTM    0          500    0          \n",
       "319  conll04  linear       0        LSTM    0          500    0          \n",
       "292  conll04  embedding    0        LSTM    0          500    0          \n",
       "316  conll04  linear       0        LSTM    0          500    0          \n",
       "265  conll04  linear       0        LSTM    0          500    1          \n",
       "289  conll04  embedding    0        LSTM    0          500    0          \n",
       "256  conll04  embedding    0        LSTM    0          500    1          \n",
       "250  conll04  embedding    0        LSTM    0          500    1          \n",
       "283  conll04  linear       0        LSTM    0          500    1          \n",
       "241  conll04  embedding    0        LSTM    0          500    1          \n",
       "304  conll04  embedding    0        LSTM    0          500    0          \n",
       "268  conll04  linear       0        LSTM    0          500    1          \n",
       "\n",
       "     par_rnn_h par_type  par_gnn_layers  seed  training_steps  \n",
       "238  400        simple   0               3     2000            \n",
       "298  400        simple   0               3     2000            \n",
       "277  400        simple   0               2     2000            \n",
       "310  400        simple   0               1     2000            \n",
       "313  400        simple   0               3     2000            \n",
       "319  400        simple   0               2     2000            \n",
       "292  400        simple   0               1     2000            \n",
       "316  400        simple   0               0     2000            \n",
       "265  400        simple   0               3     2000            \n",
       "289  400        simple   0               0     2000            \n",
       "256  400        simple   0               2     2000            \n",
       "250  400        simple   0               1     2000            \n",
       "283  400        simple   0               0     2000            \n",
       "241  400        simple   0               0     2000            \n",
       "304  400        simple   0               2     2000            \n",
       "268  400        simple   0               1     2000            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'conll04'\n",
    "df_bert_large = df[df['name'] == 'bert-large-uncased']\n",
    "df_bert_large = df_bert_large[df_bert_large['data'] == dataset]\n",
    "df_bert_large = df_bert_large.sort_values('test_f1')\n",
    "# print(df_bert_large['test_f1'].describe())\n",
    "display(df_bert_large)\n",
    "df_deberta_large = df[df['name'] == 'microsoft/deberta-v3-large']\n",
    "df_deberta_large = df_deberta_large[df_deberta_large['data'] == dataset]\n",
    "df_deberta_large = df_deberta_large.sort_values('test_f1')\n",
    "# print(df_deberta_large['test_f1'].describe())\n",
    "display(df_deberta_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM ablations no tagger rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations'\n",
    "df_no_tagger_load = load_results(walk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_tagger = df_no_tagger_load.drop_duplicates()\n",
    "df_no_tagger = df_no_tagger[df_no_tagger['metric'] == 'parser_labeled_results']\n",
    "# df_no_tagger = df_no_tagger[df_no_tagger['tag_emb'] == '0']\n",
    "# df_no_tagger = df_no_tagger[df_no_tagger['mlp_h'] == '500']\n",
    "# df_no_tagger = df_no_tagger[df_no_tag ger['par_rnn_l'] == '2']\n",
    "# df_no_tagger = df_no_tagger[df_no_tagger['seed'] == '1']\n",
    "# df_no_tagger = df_no_tagger[df_no_tagger['data'] == 'yamakata']\n",
    "\n",
    "# display(df_no_tagger)\n",
    "dataset_list = df_no_tagger['data'].unique()\n",
    "print(f'Samples with no tagger LSTM: {len(df_no_tagger)}')\n",
    "df_no_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM ablations w/ tagger rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations_tagger_rnn'\n",
    "df_tagger_load = load_results(walk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tagger = df_tagger_load.drop_duplicates()\n",
    "df_tagger = df_tagger[df_tagger['metric'] == 'parser_labeled_results']\n",
    "df_tagger = df_tagger[df_tagger['tag_rnn'] == 1] # we have this here because some experiments with tag_rnn == 1 were mistakenly saved in this folder and then we just re-ran them in the no_tagger dir without removing them from the tagger dir\n",
    "# df_tagger = df_tagger[df_tagger['tag_emb'] == '0']\n",
    "# df_tagger = df_tagger[df_tagger['mlp_h'] == '500']\n",
    "# df_tagger = df_tagger[df_tagger['par_rnn_l'] == '2']\n",
    "# df_tagger = df_tagger[df_tagger['seed'] == '1']\n",
    "# df_tagger = df_tagger[df_tagger['data'] == 'yamakata']\n",
    "\n",
    "# display(df_tagger)\n",
    "dataset_list = df_tagger['data'].unique()\n",
    "print(f'Samples with tagger LSTM: {len(df_tagger)}')\n",
    "df_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x4 charts (top LSTM hidden, top MLP out dim), one fig/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Computer Modern Roman'],\n",
    "})\n",
    "dataset_list = [\n",
    "    'ade',\n",
    "    'conll04',\n",
    "    'scierc',\n",
    "    'yamakata',\n",
    "]\n",
    "tag_emb_options = [\n",
    "    0,\n",
    "    1,\n",
    "    ]  # sorted(df_filtered['tag_emb'].unique())\n",
    "df_list = [\n",
    "    df_tagger,\n",
    "    df_no_tagger,\n",
    "    ]\n",
    "grouping_cols = [\n",
    "                # 'metric',\n",
    "                'mlp_h',\n",
    "                'par_rnn_l',\n",
    "                'par_rnn_h',\n",
    "                'arc_norm',\n",
    "                'params',\n",
    "                'data',\n",
    "                ]\n",
    "df_counter = 0\n",
    "x_criterion = 'par_rnn_l'\n",
    "color_criterion = 'mlp_h'\n",
    "font_size_big = 60\n",
    "font_size_med = 40\n",
    "\n",
    "overall_best_list = []\n",
    "\n",
    "save_flag = False\n",
    "\n",
    "for df_filtered in df_list:\n",
    "    tagger_rnn_flag = df_filtered['tag_rnn'].unique()\n",
    "    hidden_dims = sorted(df_filtered['par_rnn_h'].unique())[1:]\n",
    "    mlp_out_dims = sorted(df_filtered['mlp_h'].unique())\n",
    "    display(df_filtered)\n",
    "    for tag_emb_opt in tag_emb_options:\n",
    "        df_tag_emb = df_filtered[df_filtered['tag_emb'] == tag_emb_opt]\n",
    "        a = 1\n",
    "        b = 4\n",
    "        f, axs = plt.subplots(a,\n",
    "                            b,\n",
    "                            sharex=True,\n",
    "                            # sharey=True,\n",
    "                            figsize=(b * 10, a * 10))\n",
    "        # f.tight_layout(rect=[0, 0, 1, 1])\n",
    "        # f.suptitle(f'Test F1 vs LSTM layer number. Tagger RNN = {tagger_rnn_flag[0]}. Tag Emb = {tag_emb_opt}.', fontsize = 18)\n",
    "        # f.supxlabel(r'$L_\\psi$', fontsize=font_size_big)       # global x-axis label\n",
    "        # f.supylabel('Test F1 score', fontsize=font_size_big)   # global y-axis label\n",
    "        f.subplots_adjust(bottom=0.20, left=0.06)\n",
    "        df_best_list = []\n",
    "        for i, dataset in enumerate(sorted(dataset_list)):\n",
    "            df_combined_list_hdim = []\n",
    "            best_mean_list_hdim = []\n",
    "            df_data = df_tag_emb[df_tag_emb['data'] == dataset]\n",
    "            # CHECK ACROSS LSTM HIDDEN DIMENSIONS\n",
    "            for h_dim in hidden_dims:\n",
    "                df_grouped_hdim = (df_data[df_data['par_rnn_h'] == h_dim]\n",
    "                    .groupby(grouping_cols)['test_f1']\n",
    "                    .agg(['mean', 'std'])\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'mean': 'test_f1', 'std': 'df_std'})\n",
    "                ).sort_values(x_criterion)\n",
    "\n",
    "                df_zero_hdim = (df_data[df_data['par_rnn_h'] == 0]\n",
    "                    .groupby(grouping_cols)['test_f1']\n",
    "                    .agg(['mean', 'std'])\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'mean': 'test_f1', 'std': 'df_std'})\n",
    "                ).sort_values(x_criterion)\n",
    "\n",
    "                df_combined_hdim = pd.concat([df_zero_hdim, df_grouped_hdim])\n",
    "\n",
    "                df_combined_list_mlp_out = []\n",
    "                best_mean_list_mlp_out = []\n",
    "                # CHECK ACROSS MLP OUTPUT DIMENSIONS\n",
    "                for mlp_out in mlp_out_dims:                    \n",
    "                    df_grouped_mlp_out = df_combined_hdim[df_combined_hdim['mlp_h'] == mlp_out]\n",
    "\n",
    "                    test_f1_norm_mean_mlp_out = df_grouped_mlp_out[(df_grouped_mlp_out['arc_norm'] == 1) & (df_grouped_mlp_out['par_rnn_h'] != 0)]['test_f1'].mean()\n",
    "                    # print(f'test_f1_norm_mean_mlp_out', test_f1_norm_mean_mlp_out)\n",
    "                    test_f1_raw_mean_mlp_out = df_grouped_mlp_out[(df_grouped_mlp_out['arc_norm'] == 0) & (df_grouped_mlp_out['par_rnn_h'] != 0)]['test_f1'].mean()\n",
    "                    # print(f'test_f1_raw_mean_mlp_out', test_f1_raw_mean_mlp_out)\n",
    "                    df_grouped_mlp_out = df_grouped_mlp_out.sort_values(by=['arc_norm', 'mlp_h', 'par_rnn_l', 'par_rnn_h'])\n",
    "                    df_combined_list_mlp_out.append(df_grouped_mlp_out)\n",
    "                    # display(df_grouped_mlp_out)\n",
    "                    best_mean_list_mlp_out.append(max(test_f1_norm_mean_mlp_out, test_f1_raw_mean_mlp_out))\n",
    "                \n",
    "                best_mean_array_mlp_out = np.array(best_mean_list_mlp_out)\n",
    "                best_df_idx_mlp_out = best_mean_array_mlp_out.argmax()\n",
    "                df_best_mlp_out = df_combined_list_mlp_out[best_df_idx_mlp_out]\n",
    "                # display(df_best_mlp_out)\n",
    "\n",
    "                test_f1_norm_mean = df_best_mlp_out[(df_best_mlp_out['arc_norm'] == 1) & (df_best_mlp_out['par_rnn_h'] != 0)]['test_f1'].mean()\n",
    "                # print(f'test_f1_norm_mean', test_f1_norm_mean)\n",
    "                test_f1_raw_mean = df_best_mlp_out[(df_best_mlp_out['arc_norm'] == 0) & (df_best_mlp_out['par_rnn_h'] != 0)]['test_f1'].mean()\n",
    "                # print(f'test_f1_raw_mean', test_f1_raw_mean)\n",
    "                # print(test_f1_norm_mean > test_f1_raw_mean)\n",
    "                df_best_mlp_out = df_best_mlp_out.sort_values(by=['arc_norm', 'mlp_h', 'par_rnn_l', 'par_rnn_h'])\n",
    "                df_combined_list_hdim.append(df_best_mlp_out)\n",
    "                best_mean_list_hdim.append(max(test_f1_norm_mean, test_f1_raw_mean))\n",
    "\n",
    "            # I need to pick the dataframe with the highest mean test f1 (which is always with arc_norm == 1)\n",
    "            best_mean_array = np.array(best_mean_list_hdim)\n",
    "            best_df_idx = best_mean_array.argmax()\n",
    "            df_best = df_combined_list_hdim[best_df_idx]\n",
    "            # reorder columns\n",
    "            df_best_list.append(df_best)\n",
    "            # display(df_best)\n",
    "            data_name = data_name_dict[df_best['data'].unique()[0]]\n",
    "            df_norm_best = df_best[(df_best['arc_norm'] == 1)]\n",
    "            df_raw_best = df_best[(df_best['arc_norm'] == 0)]\n",
    "\n",
    "            x = df_norm_best[x_criterion].astype(int).tolist()\n",
    "            f1_norm_best = df_norm_best['test_f1'].tolist()\n",
    "            f1_raw_best = df_raw_best['test_f1'].tolist()\n",
    "            std_norm_best = df_norm_best['df_std'].tolist()\n",
    "            std_raw_best = df_raw_best['df_std'].tolist()\n",
    "\n",
    "            norm_scaling = 1 if df_norm_best['arc_norm'].unique()[0] == 1 else r'$\\frac{1}{\\sqrt{d}}$'\n",
    "            # print(norm_scaling)\n",
    "            raw_scaling = 1 if df_raw_best['arc_norm'].unique()[0] == 1 else r'$\\frac{1}{\\sqrt{d}}$'\n",
    "            # print(raw_scaling)\n",
    "\n",
    "            par_rnn_h_label = max(df_best['par_rnn_h'].unique())\n",
    "            h_out_label = df_raw_best[color_criterion].unique()[0]\n",
    "            tagger_rnn_flag_latex = r'\\checkmark' if tagger_rnn_flag else r'\\times'\n",
    "            tag_emb_opt_latex = r'\\checkmark' if tag_emb_opt else r'\\times'\n",
    "            figtitle = f\"{data_name} @ \" + r\"$\\psi_h$\" + f\" = {max(df_best['par_rnn_h'].unique())}, \" + \\\n",
    "                    r\"$h_{out}$ = \" + f\"{df_raw_best[color_criterion].unique()[0]} \" + \\\n",
    "                    r\"$\\phi$\" + f\" = {tagger_rnn_flag_latex} \" + \\\n",
    "                    r\"$\\textbf{e}_i^{tag} = \\times$\" + f\" = {tagger_rnn_flag_latex}\"\n",
    "            setting_string = f'tagrnn{tagger_rnn_flag[0]}-tagemb{tag_emb_opt}'\n",
    "            results_dir = os.path.join(paper_dir, setting_string)\n",
    "            if not os.path.exists(results_dir):\n",
    "                os.makedirs(results_dir)\n",
    "            # df_best.to_csv(os.path.join(results_dir, f'{data_name}_{par_rnn_h_label}_{h_out_label}.csv'), float_format = '%.3f')\n",
    "            filename_graph = f'{data_name}-hlstm{par_rnn_h_label}-hout{h_out_label}'\n",
    "            reordered_cols = ['arc_norm', 'par_rnn_l', 'params', 'test_f1', 'df_std',]\n",
    "            df_save = df_best[reordered_cols]\n",
    "            if save_flag:\n",
    "                df_save.to_latex(os.path.join(results_dir, f'{filename_graph}.tex'),\n",
    "                            float_format = '%.3f',\n",
    "                            escape = True,\n",
    "                            index=False,\n",
    "                            caption=f'Results on {figtitle}.',\n",
    "                            label=f'{filename_graph}-{setting_string}',\n",
    "                            )\n",
    "\n",
    "            # Normalized curves with error bars\n",
    "            axs[i].errorbar(x, f1_norm_best, yerr=std_norm_best, fmt='-o', capsize=3, color='#BE4D49', label=f\"a = {norm_scaling}\", linewidth = 3)\n",
    "                        # \\ + \", $|\\Theta|/10^{6} = $ {df_norm_best['params'].tolist()}\")\n",
    "            axs[i].errorbar(x, f1_raw_best, yerr=std_raw_best, fmt='-o', capsize=3, color='#3E7A7C', label=f\"a = {raw_scaling}\", linewidth = 3)\n",
    "                        # \\ + \", $|\\Theta|/10^{6} = $ {df_raw_best['params'].tolist()}\")\n",
    "            # mean_std_norm = [np.array(el).mean() for el in zip(std_norm_best, std_norm_2, std_norm_3)]\n",
    "            # mean_std_raw = [np.array(el).mean() for el in zip(std_raw_best, std_raw_2, std_raw_3)]\n",
    "            # axs[i].plot(x, mean_std_norm, marker='o', linestyle='-', label='mean std (norm)', color='black')\n",
    "            # axs[i].plot(x, mean_std_raw, marker='o', linestyle='--', label='mean std (raw)', color='black')\n",
    "\n",
    "            # axs[i].grid(True)\n",
    "            \n",
    "            # axs[i].set_title(figtitle, fontsize = font_size_big, y = 1.05)\n",
    "            axs[i].set_title(f\"{data_name} @ ({par_rnn_h_label}, {h_out_label})\", fontsize = font_size_big, y = 1.05)\n",
    "            # axs[i].legend(loc='best', fontsize=font_size_med)\n",
    "\n",
    "        grouping_cols_mean = [\n",
    "                # 'metric',\n",
    "                # 'mlp_h',\n",
    "                'par_rnn_l',\n",
    "                # 'par_rnn_h',\n",
    "                'arc_norm',\n",
    "                # 'params',\n",
    "                # 'data',\n",
    "                # 'df_std'\n",
    "                ]\n",
    "        df_mean_data = pd.concat(df_best_list).groupby(by=grouping_cols_mean)['test_f1'].agg(['mean', 'std']).reset_index().rename(columns={'mean': 'test_f1', 'std': 'df_std'}).reset_index()\n",
    "        mean_data_title = f\"{data_name} w/ tagger_rnn_flag = {tagger_rnn_flag[0]}, tag_emb = {tag_emb_opt}\"\n",
    "        print(mean_data_title)\n",
    "        display(df_mean_data)\n",
    "        df_norm_mean_best = df_mean_data[(df_mean_data['arc_norm'] == 1)]\n",
    "        df_raw_mean_best = df_mean_data[(df_mean_data['arc_norm'] == 0)]\n",
    "\n",
    "        x = df_norm_mean_best[x_criterion].astype(int).tolist()\n",
    "        f1_norm_mean_best = df_norm_mean_best['test_f1'].tolist()\n",
    "        print(np.mean(f1_norm_mean_best))\n",
    "        overall_best_list.append(np.mean(f1_norm_mean_best))\n",
    "\n",
    "        f1_raw_mean_best = df_raw_mean_best['test_f1'].tolist()\n",
    "        std_norm_mean_best = df_norm_mean_best['df_std'].tolist()\n",
    "        print(np.mean(f1_raw_mean_best))\n",
    "        std_raw_mean_best = df_raw_mean_best['df_std'].tolist()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        # Normalized curves with error bars\n",
    "        norm_scaling = 1 if df_norm_mean_best['arc_norm'].unique()[0] == 1 else r'$\\frac{1}{\\sqrt{d}}$'\n",
    "        # print(norm_scaling)\n",
    "        raw_scaling = 1 if df_raw_mean_best['arc_norm'].unique()[0] == 1 else r'$\\frac{1}{\\sqrt{d}}$'\n",
    "        # print(raw_scaling)\n",
    "        # axs[i].errorbar(x, f1_norm_mean_best, yerr=std_norm_mean_best, fmt='-o', capsize=3, label=f\"a = {norm_scaling}\", color='#BE4D49', linewidth = 3)\n",
    "        # axs[i].errorbar(x, f1_raw_mean_best, yerr=std_raw_mean_best, fmt='-o', capsize=3, label=f\"a = {raw_scaling}\", color='#3E7A7C', linewidth = 3)\n",
    "        # # axs[i].grid(True)\n",
    "        # axs[i].set_title(r\"$\\bigcup_i^4 \\mathcal(D)$\", fontsize = font_size_big, y = 1.05)\n",
    "        # axs[i].legend(loc='best', fontsize=font_size_med)\n",
    "        # integer xâ€ticks\n",
    "        # xticks = sorted(df_grouped[x_criterion].astype(int).unique())\n",
    "        # plt.xticks(xticks)\n",
    "        \n",
    "        # plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "        # plt.xlabel(x_criterion)\n",
    "        # plt.ylabel(\"Test F1 Score\")\n",
    "        # plt.legend(bbox_to_anchor=(0, 0, 1, 1))\n",
    "        for ax in axs:\n",
    "            ax.tick_params(axis='x', labelsize=font_size_med)\n",
    "            ax.tick_params(axis='y', labelsize=font_size_med+5)\n",
    "        filename = f'{a}x{b}-tagrnn{tagger_rnn_flag[0]}-tagemb{tag_emb_opt}.pdf'\n",
    "        if save_flag:\n",
    "            plt.savefig(os.path.join(paper_dir, filename), format = 'pdf')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "overall_best = np.array(overall_best_list).argmax()\n",
    "overall_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAG RNN ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations_tagger_rnn'\n",
    "df_tagger_load = load_results(walk_path)\n",
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations'\n",
    "df_no_tagger_load = load_results(walk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_tagger = df_no_tagger_load\n",
    "df_no_tagger = df_no_tagger[df_no_tagger['tag_rnn'] == 0]\n",
    "df_no_tagger = df_no_tagger[df_no_tagger['tag_emb'] == 1]\n",
    "df_no_tagger_ablation = df_no_tagger[df_no_tagger['metric'] == 'parser_labeled_results']\n",
    "# print(df_no_tagger_ablation['par_rnn_h'].value_counts())\n",
    "\n",
    "hyperparameter_list = [(300, 100, 'ade'),\n",
    "                       (400, 300, 'conll04'),\n",
    "                       (400, 500, 'scierc'),\n",
    "                       (200, 300, 'yamakata'),\n",
    "                       ]\n",
    "\n",
    "df_no_tagger_ablation_0 = df_no_tagger_ablation[(df_no_tagger_ablation['data'] == hyperparameter_list[0][2]) & (df_no_tagger_ablation['par_rnn_h'] == 0)]\n",
    "df_no_tagger_ablation_0_grouped = df_no_tagger_ablation_0.groupby(by=['data',\n",
    "                                                   'par_rnn_l',\n",
    "                                                   'arc_norm',\n",
    "                                                   'tag_emb',\n",
    "                                                   ])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "# display(df_no_tagger_ablation_0_grouped)\n",
    "\n",
    "df_no_tagger_ablation_no_0 = df_no_tagger_ablation[(df_no_tagger_ablation['data'] == hyperparameter_list[0][2]) & (df_no_tagger_ablation['par_rnn_h'] == hyperparameter_list[0][0]) & (df_no_tagger_ablation['mlp_h'] == hyperparameter_list[0][1])]\n",
    "df_no_tagger_grouped_no_0 = df_no_tagger_ablation_no_0.groupby(by=['data',\n",
    "                                                   'par_rnn_l',\n",
    "                                                   'arc_norm',\n",
    "                                                   'tag_emb',\n",
    "                                                   ])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "# display(df_no_tagger_grouped_no_0)\n",
    "\n",
    "df_no_tagger_grouped = pd.concat([df_no_tagger_ablation_0_grouped, df_no_tagger_grouped_no_0])\n",
    "df_no_tagger_grouped = df_no_tagger_grouped.sort_values(['data', 'par_rnn_l']).round(3)\n",
    "df_no_tagger_grouped['F1'] = df_no_tagger_grouped.apply(lambda row: f\"${row['mean']}\"+r\"\\pm \"+f\"{row['std']}$\", axis= 1)\n",
    "df_no_tagger_grouped = df_no_tagger_grouped.pivot(columns='data',\n",
    "                                            index=['arc_norm',\n",
    "                                                    'par_rnn_l',\n",
    "                                                    # 'tag_emb',\n",
    "                                                    ],\n",
    "                                            values=['F1'],\n",
    "                                            )\n",
    "# df_no_tagger_grouped.to_latex(os.path.join(paper_dir, f'tag_lstm_ablation_results_{hyperparameter_list[0][0]}_{hyperparameter_list[0][1]}.tex'),\n",
    "#                             float_format = '%.3f',\n",
    "#                             escape = True,\n",
    "#                             # index=False,\n",
    "#                             caption=f'Tagger BiLSTM ablation results.',\n",
    "#                             label=f'tab:tag-lstm-ablation-results',\n",
    "#                             )\n",
    "# print(df_no_tagger_grouped)\n",
    "\n",
    "# assume df_no_tagger_ablation already = df_no_tagger[(â€¦filtersâ€¦)&(metric=='parser_labeled_results')]\n",
    "\n",
    "hyperparameter_list = [\n",
    "    (300, 100, 'ade'),\n",
    "    (400, 300, 'conll04'),\n",
    "    (400, 500, 'scierc'),\n",
    "    (200, 300, 'yamakata'),\n",
    "]\n",
    "\n",
    "all_grouped = []\n",
    "\n",
    "for par_h, mlp_h, dname in hyperparameter_list:\n",
    "    # 1) the â€œzeroâ€headâ€ ablation for this dataset\n",
    "    zero = df_no_tagger_ablation[\n",
    "        (df_no_tagger_ablation['data']   == dname) &\n",
    "        (df_no_tagger_ablation['par_rnn_h'] == 0)\n",
    "    ]\n",
    "    g0 = ( zero\n",
    "           .groupby(['arc_norm','par_rnn_l'])['test_f1']\n",
    "           .agg(['mean','std'])\n",
    "           .reset_index()\n",
    "         )\n",
    "    g0['F1'] = g0.apply(lambda r: f\"${r['mean']:.3f}\\\\pm{r['std']:.3f}$\", axis=1)\n",
    "\n",
    "    # 2) the â€œfullâ€headâ€ run for this dataset\n",
    "    full = df_no_tagger_ablation[\n",
    "        (df_no_tagger_ablation['data']   == dname) &\n",
    "        (df_no_tagger_ablation['par_rnn_h'] == par_h) &\n",
    "        (df_no_tagger_ablation['mlp_h']     == mlp_h)\n",
    "    ]\n",
    "    g1 = ( full\n",
    "           .groupby(['arc_norm','par_rnn_l'])['test_f1']\n",
    "           .agg(['mean','std'])\n",
    "           .reset_index()\n",
    "         )\n",
    "    g1['F1'] = g1.apply(lambda r: f\"${r['mean']:.3f}\\\\pm{r['std']:.3f}$\", axis=1)\n",
    "\n",
    "    # 3) combine ablation + full, label by dataset\n",
    "    combined = pd.concat([g0, g1], ignore_index=True)\n",
    "    combined['dataset'] = dname\n",
    "    all_grouped.append(combined[['arc_norm','par_rnn_l','dataset','F1']])\n",
    "\n",
    "# 4) make one big long DF, then pivot so each dataset is its own column\n",
    "df_long = pd.concat(all_grouped, ignore_index=True)\n",
    "df_wide = ( df_long\n",
    "            .pivot(index=['arc_norm','par_rnn_l'],\n",
    "                   columns='dataset',\n",
    "                   values='F1')\n",
    "            .sort_index(axis=0)\n",
    "            .sort_index(axis=1)\n",
    "          )\n",
    "\n",
    "# 5) export exactly as you did before\n",
    "outname = f'tag_lstm_ablation_results.tex'\n",
    "df_wide.to_latex(\n",
    "    os.path.join(paper_dir, outname),\n",
    "    escape=True,\n",
    "    caption='Tagger BiLSTM ablation results.',\n",
    "    label='tab:tag-lstm-ablation-results'\n",
    ")\n",
    "\n",
    "# 6) inspect\n",
    "display(df_wide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Emb ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tagger = df_tagger_load\n",
    "df_tagger = df_tagger[df_tagger['tag_rnn'] == 0]\n",
    "df_tagger = df_tagger[df_tagger['tag_emb'] == 1]\n",
    "print(len(df_tagger))\n",
    "df_tagger_ablation = df_tagger[df_tagger['metric'] == 'parser_labeled_results']\n",
    "# print(df_tagger_ablation['par_rnn_h'].value_counts())\n",
    "df_tagger_ablation_0 = df_tagger_ablation[(df_tagger_ablation['par_rnn_h'] == 0)]\n",
    "df_tagger_ablation_0_grouped = df_tagger_ablation_0.groupby(by=['data',\n",
    "                                                   'par_rnn_l',\n",
    "                                                   'arc_norm',\n",
    "                                                   'tag_emb',\n",
    "                                                   ])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "# display(df_tagger_ablation_0_grouped)\n",
    "df_tagger_ablation_0 = df_tagger_ablation[(df_tagger_ablation['par_rnn_h'] == 300) & (df_tagger_ablation['mlp_h'] == 100)]\n",
    "df_tagger_grouped_0 = df_tagger_ablation_0.groupby(by=['data',\n",
    "                                                   'par_rnn_l',\n",
    "                                                   'arc_norm',\n",
    "                                                   'tag_emb',\n",
    "                                                   ])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "# display(df_tagger_grouped_0)\n",
    "\n",
    "df_tagger_grouped = pd.concat([df_tagger_ablation_0_grouped, df_tagger_grouped_0])\n",
    "df_tagger_grouped = df_tagger_grouped.sort_values(['data', 'par_rnn_l']).round(3)\n",
    "df_tagger_grouped['F1'] = df_tagger_grouped.apply(lambda row: f\"${row['mean']}\"+r\"\\pm \"+f\"{row['std']}$\", axis= 1)\n",
    "df_tagger_grouped = df_tagger_grouped.pivot(columns='data',\n",
    "                                            index=['arc_norm',\n",
    "                                                    'par_rnn_l',\n",
    "                                                    'tag_emb',\n",
    "                                                    ],\n",
    "                                            values=['F1'],\n",
    "                                            )\n",
    "df_tagger_grouped.to_latex(os.path.join(paper_dir, f'tag_embeddings_ablation_results.tex'),\n",
    "                            float_format = '%.3f',\n",
    "                            escape = True,\n",
    "                            # index=False,\n",
    "                            caption=f'Tag embeddings ablation results.',\n",
    "                            label=f'tab:tag-embeddings-ablation-results',\n",
    "                            )\n",
    "df_tagger_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FT Deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_results_dir = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_fullft_xu_low_lr'\n",
    "ft_results = load_results(ft_results_dir)\n",
    "print(ft_results['seed'].value_counts())\n",
    "ft_results = ft_results[ft_results['metric'] == 'parser_labeled_results']\n",
    "# display(ft_results[ft_results['data'] == 'scierc'])\n",
    "ft_results_grouped = ft_results.groupby(by=['data',\n",
    "                                            'name',\n",
    "                                            'tag_emb',\n",
    "                                            # 'freeze_enc',\n",
    "                                            'arc_norm'])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "ft_results_grouped = ft_results_grouped.round(3)\n",
    "ft_results_grouped['F1'] = ft_results_grouped.apply(lambda x: f\"{x['mean']} $\\\\pm {x['std']}$\", axis = 1)\n",
    "ft_results_grouped = ft_results_grouped.pivot(\n",
    "    columns=['data'],\n",
    "    index=['arc_norm', 'tag_emb', 'name'],\n",
    "    values=['F1']\n",
    ")\n",
    "ft_results_grouped.to_latex(os.path.join(paper_dir, f'tag_embeddings_ablation_results.tex'),\n",
    "                            float_format = '%.3f',\n",
    "                            escape = True,\n",
    "                            # index=False,\n",
    "                            caption=f'Tag embeddings ablation results.',\n",
    "                            label=f'tab:ft-deberta-results',\n",
    "                            )\n",
    "ft_results_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convergence graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Computer Modern Roman'],\n",
    "})\n",
    "paper_dir_best = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/paper_results_xavier_uniform'\n",
    "walk_path_convergence = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_best_xu'\n",
    "entries = []\n",
    "dataset_list = ['ade', 'conll04', 'scierc', 'yamakata']\n",
    "for root, dirs, files in os.walk(walk_path_convergence):\n",
    "    for F in files:\n",
    "        filename = os.path.join(root, F)\n",
    "        if filename.endswith('config.json'):\n",
    "            config = json.load(open(os.path.join(root, 'config.json')))\n",
    "            val_results_graph = json.load(open(os.path.join(root, 'val_results.json')))\n",
    "            val_results = config['val_results']\n",
    "            test_results = config['test_results']\n",
    "            entries.append({\n",
    "                'dataset_name': config['config']['dataset_name'],\n",
    "                'arc_norm': config['config']['arc_norm'],\n",
    "                'steps': [el['steps'] for el in val_results_graph],\n",
    "                'f1': [el['parser_labeled_results']['F1'] for el in val_results_graph],\n",
    "            })\n",
    "# df_convergence = pd.DataFrame.from_records(entries)\n",
    "# df_convergence#.groupby(by=['dataset_name', 'arc_norm'])\n",
    "grouped_dict = {}\n",
    "for dataset_name in dataset_list:\n",
    "    for arc_opt in [0, 1]:\n",
    "        grouped_dict[(dataset_name, arc_opt)] = []\n",
    "length_list = []\n",
    "for dataset_name in dataset_list:\n",
    "    for arc_opt in [0, 1]:\n",
    "        for entry in entries:\n",
    "            if entry['dataset_name'] == dataset_name and entry['arc_norm'] == arc_opt:\n",
    "                grouped_dict[(dataset_name, arc_opt)].append(entry['f1'])\n",
    "                length_list.append(len(entry['f1']))\n",
    "\n",
    "grouped_mean = {}\n",
    "grouped_count = {}\n",
    "\n",
    "for key, value_list in grouped_dict.items():\n",
    "    # build nan-padded array\n",
    "    max_len = max(len(s) for s in value_list)\n",
    "    arr = np.full((len(value_list), max_len), np.nan, dtype=float)\n",
    "    for i, series in enumerate(value_list):\n",
    "        arr[i, :len(series)] = series\n",
    "\n",
    "    # mean & count\n",
    "    grouped_mean[key]  = np.nanmean(arr, axis=0)\n",
    "    grouped_count[key] = np.sum(~np.isnan(arr), axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 5),\n",
    "                         sharey=True,\n",
    "                        #  sharex=True,\n",
    "                         )\n",
    "colors = ['#3E7A7C', '#BE4D49']\n",
    "for idx, dataset in enumerate(dataset_list):\n",
    "    ax = axes[idx]\n",
    "    for arc_opt in [0, 1]:\n",
    "        mean_s  = grouped_mean[(dataset, arc_opt)]\n",
    "        count_s = grouped_count[(dataset, arc_opt)]\n",
    "        idxs    = np.arange(len(mean_s))\n",
    "        total_runs = count_s.max()\n",
    "\n",
    "        ax.plot(idxs, mean_s, label=f\"arc_norm={arc_opt}\", linewidth = 3, color = colors[arc_opt])\n",
    "        ax.fill_between(\n",
    "            idxs,\n",
    "            mean_s,\n",
    "            where=(count_s < total_runs),\n",
    "            alpha=0.2,\n",
    "            label=f\"Early stopping (arc_norm={arc_opt})\",\n",
    "            color = colors[arc_opt]\n",
    "        )\n",
    "\n",
    "    # â† only every 5th index (i.e. 500 steps) gets a tick\n",
    "    tick_idxs = np.arange(0, len(idxs), 5)\n",
    "    ax.tick_params(axis='both', labelsize=25)\n",
    "    ax.set_xticks(tick_idxs)\n",
    "    ax.set_xticklabels(tick_idxs * 100)\n",
    "\n",
    "    ax.set_title(data_name_dict[dataset], fontsize=35)\n",
    "    # ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(paper_dir_best, 'convergence.pdf'), format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Bhatt setting (original repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/mtrfg_results_og_repo'\n",
    "entries = []\n",
    "metric_list = ['tagger_results', 'parser_labeled_results', 'parser_unlabeled_results',]\n",
    "for root, dirs, files in os.walk(walk_path):\n",
    "    for F in files:\n",
    "        filename = os.path.join(root, F)\n",
    "        if filename.endswith('config.json'):\n",
    "            config = json.load(open(os.path.join(root, 'config.json')))\n",
    "            # print(config)\n",
    "            val_results = json.load(open(os.path.join(root, 'val_results_best.json')))\n",
    "            test_results = json.load(open(os.path.join(root, 'test_results.json')))\n",
    "            for metric in metric_list:\n",
    "                entry = {\n",
    "                \"metric\": metric,\n",
    "                \"arc_norm\": config['arc_norm'],\n",
    "                \"val_p\": val_results[metric]['P'],\n",
    "                \"val_r\": val_results[metric]['R'],\n",
    "                \"val_f1\": val_results[metric]['F1'],\n",
    "                \"test_p\": test_results[metric]['P'],\n",
    "                \"test_r\": test_results[metric]['R'],\n",
    "                \"test_f1\": test_results[metric]['F1'],}\n",
    "                entries.append(entry)\n",
    "df_bhatt_og = pd.DataFrame.from_records(entries)\n",
    "df_bhatt_og_group_p = df_bhatt_og.groupby(by=['metric', 'arc_norm'])['test_p'].agg(['mean', 'std']).reset_index()\n",
    "df_bhatt_og_group_p = df_bhatt_og_group_p.round(3)\n",
    "\n",
    "df_bhatt_og_group_p['combined'] = df_bhatt_og_group_p.apply(lambda row: f\"{row['mean']} pm {row['std']}\", axis= 1)\n",
    "df_bhatt_og_group_p = df_bhatt_og_group_p.pivot(index='arc_norm', columns='metric', values=['combined'])\n",
    "print('precision')\n",
    "display(df_bhatt_og_group_p)\n",
    "df_bhatt_og_group_r = df_bhatt_og.groupby(by=['metric', 'arc_norm'])['test_r'].agg(['mean', 'std']).reset_index()\n",
    "df_bhatt_og_group_r = df_bhatt_og_group_r.round(3)\n",
    "\n",
    "df_bhatt_og_group_r['combined'] = df_bhatt_og_group_r.apply(lambda row: f\"{row['mean']} pm {row['std']}\", axis= 1)\n",
    "df_bhatt_og_group_r = df_bhatt_og_group_r.pivot(index='arc_norm', columns='metric', values=['combined'])\n",
    "print('recall')\n",
    "display(df_bhatt_og_group_r)\n",
    "df_bhatt_og_group_f1 = df_bhatt_og.groupby(by=['metric', 'arc_norm'])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "df_bhatt_og_group_f1 = df_bhatt_og_group_f1.round(3)\n",
    "\n",
    "df_bhatt_og_group_f1['combined'] = df_bhatt_og_group_f1.apply(lambda row: f\"{row['mean']} pm {row['std']}\", axis= 1)\n",
    "df_bhatt_og_group_f1 = df_bhatt_og_group_f1.pivot(index='arc_norm', columns='metric', values=['combined'])\n",
    "print('f1')\n",
    "display(df_bhatt_og_group_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Bhatt setting (updated repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bhatt = df_tagger\n",
    "# df_bhatt['name'] = 'bert'\n",
    "df_bhatt = df_bhatt[df_bhatt['par_rnn_l'] == 3]\n",
    "df_bhatt = df_bhatt[df_bhatt['par_rnn_h'] == 400]\n",
    "df_bhatt = df_bhatt[df_bhatt['mlp_h'] == 500]\n",
    "df_bhatt = df_bhatt[df_bhatt['tag_emb'] == 1]\n",
    "# df_bhatt = df_bhatt[df_bhatt['arc_norm'] == 0]\n",
    "df_bhatt = df_bhatt.groupby(by=['data', 'arc_norm'])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "print(len(df_bhatt))\n",
    "df_bhatt = df_bhatt.round(3)\n",
    "display(df_bhatt)\n",
    "df_bhatt['F1'] = df_bhatt.apply(lambda row: f\"${row['mean']}\"+r\"\\pm \"+f\"{row['std']}$\", axis= 1)\n",
    "df_bhatt = df_bhatt.drop(['mean', 'std'], axis = 1)\n",
    "df_bhatt.to_latex(os.path.join(paper_dir, f'bhatt_results.tex'),\n",
    "                            float_format = '%.3f',\n",
    "                            escape = True,\n",
    "                            index=False,\n",
    "                            caption=f'Bhatt results.',\n",
    "                            label=f'tab:bhatt-results',\n",
    "                            )\n",
    "display(df_bhatt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_steps_lora_ft'\n",
    "df_aggregate_ft = load_results(walk_path)\n",
    "dataset_list = [\n",
    "    'ade',\n",
    "    'conll04',\n",
    "    'scierc',\n",
    "    'yamakata'\n",
    "    ]\n",
    "\n",
    "# for dataset in dataset_list:\n",
    "    # df_aggregate_ft = df_aggregate_ft[df_aggregate_ft['data'] == dataset]\n",
    "df_aggregate_ft = df_aggregate_ft[df_aggregate_ft['metric'] == 'parser_labeled_results']\n",
    "df_aggregate_ft = df_aggregate_ft.sort_values(by='test_f1', ascending=False)\n",
    "# df_aggregate_ft = df_aggregate_ft[df_aggregate_ft['par_rnn_l'] == 3]\n",
    "\n",
    "# degrees of freedom\n",
    "# print(df_aggregate_ft['tag_emb'].value_counts())\n",
    "# print(df_aggregate_ft['arc_norm'].value_counts())\n",
    "# print(df_aggregate_ft['freeze_enc'].value_counts())\n",
    "\n",
    "display(df_aggregate_ft)\n",
    "\n",
    "df_group = (\n",
    "    df_aggregate_ft\n",
    "    .groupby(['metric',\n",
    "            'arc_norm',\n",
    "            'tag_emb',\n",
    "            # 'params',\n",
    "            'data',\n",
    "            'lora',\n",
    "            ])['test_f1']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'test_f1', 'std': 'df_std'})\n",
    ")\n",
    "\n",
    "df_group = df_group.sort_values(by=['tag_emb', 'arc_norm', 'data',])\n",
    "\n",
    "# df_group = df_group[df_group['par_rnn_l'] == 3]\n",
    "# df_group = df_group[df_group['arc_norm'] == 0]\n",
    "\n",
    "df_group.to_latex(os.path.join(paper_dir, f'ft_lora_results.tex'),\n",
    "                            float_format = '%.3f',\n",
    "                            escape = True,\n",
    "                            index=False,\n",
    "                            caption=f'Full fine-tuning and LoRA results.',\n",
    "                            label=f'tab:full-ft-lora-results',\n",
    "                            )\n",
    "display(df_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/resultstagger_gnn_xu'\n",
    "df_aggregate_gnn = load_results(walk_path)\n",
    "df_aggregate_gnn = df_aggregate_gnn[df_aggregate_gnn['metric'] == 'parser_labeled_results']\n",
    "df_aggregate_gnn = df_aggregate_gnn[df_aggregate_gnn['data'] == 'yamakata']\n",
    "# print(df_aggregate_gnn['freeze_enc'].describe())\n",
    "# print(df_aggregate_gnn['seed'].value_counts())\n",
    "display(df_aggregate_gnn)\n",
    "df_group_gnn = df_aggregate_gnn.groupby(by = ['data',\n",
    "                                              'par_rnn_l',\n",
    "                                              'par_rnn_h',\n",
    "                                              'mlp_h',\n",
    "                                              'par_gnn_layers',\n",
    "                                              'arc_norm'\n",
    "                                              ])['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "df_group_gnn.sort_values(['par_rnn_l', 'par_gnn_layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM complete results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations'\n",
    "df_no_tagger = load_results(walk_path)\n",
    "display(df_no_tagger)\n",
    "walk_path = '/home/pgajo/projects/def-hsajjad/pgajo/mtrfg_results/results_lstm_size_ablations_tagger_rnn'\n",
    "df_tagger = load_results(walk_path)\n",
    "df_tagger = df_tagger[df_tagger['tag_rnn'] == 1]\n",
    "display(df_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppp(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "tag_emb_opts = (0, 1)\n",
    "df_list = [df_tagger]\n",
    "for df in df_list:\n",
    "    for tag_emb_option in tag_emb_opts:\n",
    "        df_no_tagger_filtered = df[df['tag_emb'] == tag_emb_option]\n",
    "        # display(df_no_tagger_filtered)\n",
    "        # df_no_tagger_group_data = df_no_tagger_filtered.groupby(by=[\n",
    "        #                         'metric',\n",
    "        #                         # 'data',\n",
    "        #                         'tag_emb',\n",
    "        #                         'par_rnn_l',\n",
    "        #                         'par_rnn_h',\n",
    "        #                         'mlp_h',\n",
    "        #                         'arc_norm',\n",
    "        #                         ],)['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "        # df_no_tagger_group_data = df_no_tagger_group_data.sort_values('mean')\n",
    "        # display(df_no_tagger_group_data)\n",
    "        df_no_tagger_group = df_no_tagger_filtered.groupby(by=[\n",
    "                                'metric',\n",
    "                                'data',\n",
    "                                'tag_emb',\n",
    "                                'par_rnn_l',\n",
    "                                'par_rnn_h',\n",
    "                                'mlp_h',\n",
    "                                'arc_norm',\n",
    "                                ],)['test_f1'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        df_no_tagger_group['mean_std'] = df_no_tagger_group.apply(\n",
    "                lambda row: f\"{row['mean']:.3f} Â± {row['std']:.3f}\", axis=1\n",
    "            )\n",
    "        # df_no_tagger_group = df_no_tagger_group.drop(['mean', 'std'], axis=1)\n",
    "        df_no_tagger_group\n",
    "\n",
    "        tag_emb_flag = df_no_tagger_filtered['tag_emb'].unique()[0]\n",
    "        tag_rnn_flag = df_no_tagger_filtered['tag_rnn'].unique()[0]\n",
    "\n",
    "        pivot_df = df_no_tagger_group.pivot(\n",
    "            values=[\n",
    "                    # 'mean_std',\n",
    "                    'mean',\n",
    "                    # 'std',\n",
    "                    ],\n",
    "            index=['arc_norm',\n",
    "                    'par_rnn_l',\n",
    "                    'metric',\n",
    "                    'tag_emb',\n",
    "                    'par_rnn_h',\n",
    "                    'mlp_h',\n",
    "                    ],\n",
    "            columns='data'\n",
    "        ).reset_index()\n",
    "        display(pivot_df)\n",
    "        \n",
    "        # pivot_df['overall_mean'] = pivot_df.apply(lambda row: ppp(row))\n",
    "        \n",
    "        # pivot_df.to_latex(os.path.join(paper_dir, f'lstm_results_complete_tagemb-{tag_emb_flag}_tagrnn-{tag_rnn_flag}.tex'),\n",
    "        #                             float_format='%.3f',\n",
    "        #                             escape=True,\n",
    "        #                             # index=False,\n",
    "        #                             caption=f'Complete LSTM results - tagemb-{tag_emb_flag} - tagrnn-{tag_rnn_flag}.',\n",
    "        #                             label=f\"tab:lstm-results-complete_tagemb-{tag_emb_flag}_tagrnn-{tag_rnn_flag}\",\n",
    "        #                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
